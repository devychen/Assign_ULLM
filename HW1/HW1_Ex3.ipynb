{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task overview <br>\n",
    "**Goal**: Practice fine-tuning a pre-trained LM (GPT2-small) on the particular task of commonsense question answering (QA) <br>\n",
    "**Dataset**: [CommonsenseQA](https://huggingface.co/datasets/tau/commonsense_qa) <br>\n",
    "**Description** <br>\n",
    "- Evaluate the performance of the model on testset over training set. <br>\n",
    "- Monitor: \n",
    "    - Whether the model’s performance is improving; \n",
    "    - Compare the performance of the base pretrained GPT-2 and the fine-tuned model \n",
    "- Steps:\n",
    "    1. Data preparation. Simiar to [sheet 1.1](https://cogsciprag.github.io/Understanding-LLMs-course/tutorials/01-introduction.html#main-training-data-processing-steps) and [sheet 2.3](https://cogsciprag.github.io/Understanding-LLMs-course/tutorials/02c-MLP-pytorch.html#preparing-the-training-data)\n",
    "    2. Load the pretrained GPT-2 model\n",
    "    3. Set up training pipiline. Steps similar to [sheet 2.5](https://cogsciprag.github.io/Understanding-LLMs-course/tutorials/02e-intro-to-hf.html)\n",
    "    4. Run the training while tracking the losses\n",
    "    5. Save plot of losses for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.30.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2023.12.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# pkg preparation\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "!pip3 install accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Data Preparation\n",
    "1. Acquiring data <br>\n",
    "2. Minimally exploring dataset <br>\n",
    "3. Cleaning / wrangling data (combines step 4 from sheet 1.1 and step 1.1 above) <br>\n",
    "4. Splitting data into training and test set (we will not do any hyperparam tuning) (we don't need further training set wrangling) <br>\n",
    "5. Tokenizing data and making sure it can be batched (i.e., conversted into 2d tensors), this will also happen in our custom Dataset class (common practice when working with text data) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The keys are:\n",
      " dict_keys(['train', 'validation', 'test'])\n",
      "A sample:\n",
      " {'id': '075e483d21c29a511267ef62bedc0461', 'question': 'The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?', 'question_concept': 'punishing', 'choices': {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['ignore', 'enforce', 'authoritarian', 'yell at', 'avoid']}, 'answerKey': 'A'}\n"
     ]
    }
   ],
   "source": [
    "# downaload dataset from HF\n",
    "dataset = load_dataset(\"tau/commonsense_qa\")\n",
    "# inspect dataset, print all keys\n",
    "print(\"The keys are:\\n\", dataset.keys())\n",
    "# print a sample from the dataset\n",
    "print(\"A sample:\\n\", dataset[\"train\"][0]) # CODE\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# set padding side to be left because we are doing causal LM\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def massage_input_text(example):\n",
    "    \"\"\"\n",
    "    Helper for converting input examples which have \n",
    "    a separate qquestion, labels, answer options\n",
    "    into a single string.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    example: dict\n",
    "        Sample input from the dataset which contains the \n",
    "        question, answer labels (e.g. A, B, C, D),\n",
    "        the answer options for the question, and which \n",
    "        of the answers is correct.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    input_text: str\n",
    "        Formatted training text which contains the question,\n",
    "        the forwatted answer options (e.g., 'A. <option 1> B. <option 2>' etc)\n",
    "        and the ground truth answer.\n",
    "    \"\"\"\n",
    "    # combine each label with its corresponding text\n",
    "    answer_options_list = list(zip(\n",
    "        example[\"choices\"][\"label\"],\n",
    "        example[\"choices\"][\"text\"]\n",
    "    ))\n",
    "    # join each label and text with . and space\n",
    "    answer_options = \" \".join([f\"{label}. {text}\" for label, text in answer_options_list]) # CODE\n",
    "    # join the list of options with spaces into single string\n",
    "    answer_options_string = \" \".join(answer_options.split()) # CODE\n",
    "    # combine question and answer options\n",
    "    input_text = example[\"question\"] + \" \" + answer_options_string\n",
    "    # append the true answer with a new line, \"Answer: \" and the label\n",
    "    input_text += \"\\nAnswer: \" + example[\"answerKey\"]\n",
    "\n",
    "    return input_text\n",
    "\n",
    "# process input texts of train and test sets\n",
    "massaged_datasets = dataset.map(\n",
    "    lambda example: {\n",
    "        \"text\": massage_input_text(example)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sample from the preprocessed data:\n",
      " {'id': '075e483d21c29a511267ef62bedc0461', 'question': 'The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?', 'question_concept': 'punishing', 'choices': {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['ignore', 'enforce', 'authoritarian', 'yell at', 'avoid']}, 'answerKey': 'A', 'text': 'The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? A. ignore B. enforce C. authoritarian D. yell at E. avoid\\nAnswer: A'}\n"
     ]
    }
   ],
   "source": [
    "# inspect a sample from our preprocessed data\n",
    "prep_data_sample = massaged_datasets[\"train\"][0] # CODE, modified\n",
    "print(\"A sample from the preprocessed data:\\n\", prep_data_sample) # CODE, modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonsenseQADataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset class for CommonsenseQA dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            train_split, \n",
    "            test_split,\n",
    "            tokenizer,\n",
    "            max_length=64,\n",
    "            dataset_split=\"train\",\n",
    "        ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the dataset object.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        train_split: dict\n",
    "            Training data dictionary with different columns.\n",
    "        test_split: dict\n",
    "            Test data dictionary with different columns.\n",
    "        tokenizer: Tokenizer\n",
    "            Initialized tokenizer for processing samples.\n",
    "        max_length: int\n",
    "            Maximal length of inputs. All inputs will be \n",
    "            truncated or padded to this length.\n",
    "        dataset_split: str\n",
    "            Specifies which split of the dataset to use. \n",
    "            Default is \"train\".\n",
    "        \"\"\"\n",
    "        self.train_split = train_split['text']\n",
    "        self.test_split = test_split['text']\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.dataset_split = dataset_split\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Method returning the length of the training dataset.\n",
    "        \"\"\"\n",
    "        return len(self.train_split) if self.dataset_split == \"train\" else len(self.test_split) # CODE\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Method returning a single training example.\n",
    "        Note that it also tokenizes, truncates or pads the input text.\n",
    "        Further, it creates a mask tensor for the input text which \n",
    "        is used for causal masking in the transformer model.\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        idx: int\n",
    "            Index of training sample to be retrieved from the data.\n",
    "        \n",
    "        Returns\n",
    "        --------\n",
    "        tokenized_input: dict\n",
    "            Dictionary with input_ids (torch.Tensor) and an attention_mask\n",
    "            (torch.Tensor).\n",
    "        \"\"\"\n",
    "        # retrieve a training sample at the specified index idx\n",
    "        # HINT: note that this might depend on self.dataset_split\n",
    "        input_text = self.train_split[idx] if self.dataset_split == \"train\" else self.test_split[idx] # CODE\n",
    "        tokenized_input = self.tokenizer(\n",
    "            input_text,\n",
    "            max_length = self.max_length, # CODE\n",
    "            padding = \"max_length\",\n",
    "            truncation = True,\n",
    "            return_tensors = \"pt\"\n",
    "        )\n",
    "        tokenized_input[\"attention_mask\"] = (tokenized_input[\"input_ids\"] != tokenizer.pad_token_id).long()\n",
    "        return tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# move to accelerated device \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Device: {device}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"Device: {device}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Initialise Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 size: 124.4 M parameters\n"
     ]
    }
   ],
   "source": [
    "# load pretrained gpt2 for HF\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\") # CODE\n",
    "# print num of trainable parameters\n",
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"GPT-2 size: {model_size/1000**2:.1f} M parameters\")\n",
    "\n",
    "# Hint: If you run out of memory while trying to run the training, try decreasing the batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Set up configurations required for the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate dataset with the downloaded commonsense_qa data \n",
    "train_dataset = CommonsenseQADataset(\n",
    "    train_split = massaged_datasets[\"train\"], \n",
    "    test_split = massaged_datasets[\"test\"],\n",
    "    tokenizer = tokenizer,\n",
    "    max_length = 64, \n",
    "    dataset_split = \"train\" # CODE\n",
    ")\n",
    "# instantiate test dataset with the downloaded commonsense_qa data\n",
    "test_dataset = CommonsenseQADataset(\n",
    "    train_split = massaged_datasets[\"train\"], \n",
    "    test_split = massaged_datasets[\"test\"],\n",
    "    tokenizer = tokenizer,\n",
    "    max_length = 64, \n",
    "    dataset_split = \"test\" # CODE\n",
    ")\n",
    "# create a DataLoader for the dataset\n",
    "# the data loader will automatically batch the data\n",
    "# and iteratively return training examples (question answer pairs) in batches\n",
    "dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True\n",
    ")\n",
    "# create a DataLoader for the test dataset\n",
    "# reason for separate data loader is that we want to\n",
    "# be able to use a different index for retreiving the test batches\n",
    "# we might also want to use a different batch size etc.\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Run the training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training steps:  304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/304 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 0, loss 10.966512680053711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                        | 1/304 [00:29<2:29:46, 29.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(8.0536)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▎                                      | 10/304 [02:33<1:09:43, 14.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 10, loss 2.71817684173584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▍                                      | 11/304 [02:58<1:25:33, 17.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(2.7612)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▋                                     | 20/304 [05:03<1:05:12, 13.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 20, loss 2.241389751434326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▊                                     | 21/304 [05:33<1:27:18, 18.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(2.4157)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▏                                     | 30/304 [07:27<58:48, 12.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 30, loss 2.1551876068115234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████                                    | 31/304 [07:52<1:15:04, 16.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(2.1811)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▌                                    | 40/304 [09:48<55:30, 12.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 40, loss 1.9300326108932495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▍                                  | 41/304 [10:14<1:12:17, 16.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.9336)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▉                                   | 50/304 [12:11<53:53, 12.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 50, loss 1.8985474109649658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▋                                 | 51/304 [12:38<1:11:10, 16.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.9166)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▎                                 | 60/304 [14:29<50:20, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 60, loss 1.7412619590759277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████                                | 61/304 [14:53<1:04:08, 15.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.8910)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████▋                                | 70/304 [16:45<46:05, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 70, loss 1.8059301376342773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████▎                              | 71/304 [17:10<1:01:15, 15.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.8130)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████                               | 80/304 [19:13<46:55, 12.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 80, loss 1.703949213027954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|███████████▏                              | 81/304 [19:36<58:50, 15.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.8699)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▍                             | 90/304 [21:33<49:49, 13.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 90, loss 1.6837917566299438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████▉                            | 91/304 [22:06<1:08:56, 19.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.9634)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████▍                           | 100/304 [24:35<55:57, 16.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 100, loss 1.6681714057922363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████▉                          | 101/304 [25:07<1:11:25, 21.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.8773)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████▊                          | 110/304 [27:27<51:22, 15.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 110, loss 1.7873094081878662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████▏                        | 111/304 [27:56<1:03:42, 19.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.9629)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████▏                        | 120/304 [30:16<48:06, 15.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 120, loss 1.5906360149383545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████▎                        | 121/304 [30:45<59:15, 19.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7972)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████▌                       | 130/304 [33:23<50:10, 17.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 130, loss 1.6256121397018433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████████████████▊                      | 131/304 [33:57<1:04:01, 22.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.8323)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████▉                      | 140/304 [36:22<45:23, 16.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 140, loss 1.6109676361083984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████                      | 141/304 [36:52<55:52, 20.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7801)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████████████████████▏                    | 150/304 [39:02<36:44, 14.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 150, loss 1.6622003316879272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████▎                    | 151/304 [39:28<45:30, 17.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7585)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████▌                   | 160/304 [41:47<34:37, 14.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 160, loss 1.7394182682037354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████▋                   | 161/304 [42:15<44:07, 18.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.9057)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████▉                  | 170/304 [44:12<28:15, 12.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 170, loss 1.7609511613845825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|███████████████████████                  | 171/304 [44:37<36:23, 16.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.8741)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|████████████████████████▎                | 180/304 [46:24<23:37, 11.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 180, loss 1.6382803916931152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████▍                | 181/304 [46:48<31:26, 15.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.8300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████▋               | 190/304 [48:53<24:11, 12.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 190, loss 1.550491452217102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████▊               | 191/304 [49:17<30:28, 16.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7962)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████▉              | 200/304 [51:13<23:41, 13.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 200, loss 1.6100095510482788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|███████████████████████████              | 201/304 [51:51<35:48, 20.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7868)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████▎            | 210/304 [53:54<20:47, 13.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 210, loss 1.4915876388549805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████▍            | 211/304 [54:23<28:06, 18.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7446)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|█████████████████████████████▋           | 220/304 [56:12<17:09, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 220, loss 1.4172223806381226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|█████████████████████████████▊           | 221/304 [56:36<21:49, 15.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7829)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████          | 230/304 [58:31<15:43, 12.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 230, loss 1.4164819717407227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████████████████████████████▏         | 231/304 [58:58<20:58, 17.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7607)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████▊        | 240/304 [1:00:54<13:57, 13.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 240, loss 1.5902371406555176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████▉        | 241/304 [1:01:19<17:23, 16.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7540)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████████████████████████████       | 250/304 [1:03:23<12:52, 14.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 250, loss 1.5085529088974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████▏      | 251/304 [1:03:47<15:10, 17.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7743)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████▎     | 260/304 [1:05:39<08:40, 11.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 260, loss 1.4384350776672363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████▍     | 261/304 [1:06:05<11:31, 16.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7543)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|██████████████████████████████████▋    | 270/304 [1:07:55<07:03, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 270, loss 1.541365146636963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|██████████████████████████████████▊    | 271/304 [1:08:21<09:06, 16.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7229)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████▉   | 280/304 [1:10:13<04:59, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 280, loss 1.4068559408187866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|████████████████████████████████████   | 281/304 [1:10:37<06:07, 15.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7721)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████▏ | 290/304 [1:12:38<03:03, 13.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 290, loss 1.50174081325531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████▎ | 291/304 [1:13:02<03:35, 16.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7405)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|██████████████████████████████████████▍| 300/304 [1:14:48<00:47, 11.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 300, loss 1.4545259475708008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|██████████████████████████████████████▌| 301/304 [1:15:13<00:47, 15.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7485)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 304/304 [1:15:50<00:00, 14.97s/it]\n"
     ]
    }
   ],
   "source": [
    "# Hint: for implementing the forward pass and loss computation, carefully look at the exercise sheets \n",
    "# and the links to examples in HF tutorials.\n",
    "\n",
    "# put the model in training mode\n",
    "model.train()\n",
    "# move the model to the device (e.g. GPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# trianing configutations \n",
    "# feel free to play around with these\n",
    "epochs  = 1\n",
    "train_steps =  len(train_dataset) // 32\n",
    "print(\"Number of training steps: \", train_steps)\n",
    "# number of test steps to perform every 10 training steps\n",
    "# (smaller that the entore test split for reasons of comp. time)\n",
    "num_test_steps = 5\n",
    "\n",
    "# define optimizer and learning rate\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4) \n",
    "# define some variables to accumulate the losses\n",
    "losses = []\n",
    "test_losses = []\n",
    "\n",
    "# iterate over epochs\n",
    "for e in range(epochs):\n",
    "    # iterate over training steps\n",
    "    for i in tqdm(range(train_steps)):\n",
    "        # get a batch of data\n",
    "        x = next(iter(dataloader))\n",
    "        # move the data to the device (GPU)\n",
    "        x = {key: val.to(device) for key, val in x.items()}  # Move batch to device # CODE\n",
    "\n",
    "        # forward pass through the model \n",
    "        \n",
    "        outputs = model( \n",
    "            input_ids = x[\"input_ids\"],\n",
    "            attention_mask = x[\"attention_mask\"],\n",
    "            labels = x[\"input_ids\"]\n",
    "            # CODE\n",
    "        )\n",
    "        # get the loss\n",
    "        loss = outputs.loss # CODE\n",
    "        # backward pass\n",
    "        loss.backward() # CODE\n",
    "        losses.append(loss.item())\n",
    "        # update the parameters of the model\n",
    "        optimizer.step() # CODE\n",
    "\n",
    "        # zero out gradient for next step\n",
    "        optimizer.zero_grad() # CODE\n",
    "\n",
    "        # evaluate on test set every 10 steps\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch {e}, step {i}, loss {loss.item()}\")\n",
    "            # track test loss for the evaluation iteration\n",
    "            test_loss = 0\n",
    "            for j in range(num_test_steps):\n",
    "                # get test batch\n",
    "                x_test = next(iter(test_dataloader))\n",
    "                x_test = x_test.to(device)\n",
    "                with torch.no_grad():\n",
    "                    test_outputs = model(\n",
    "                        input_ids=x_test[\"input_ids\"],\n",
    "                        attention_mask=x_test[\"attention_mask\"],\n",
    "                        labels=x_test[\"input_ids\"] # CODE\n",
    "                    )\n",
    "                if test_outputs.loss is not None: # Check of the loss is not None\n",
    "                    test_loss += test_outputs.loss # CODE\n",
    "                \n",
    "            test_losses.append(test_loss / num_test_steps)\n",
    "            print(\"Test loss: \", test_loss/num_test_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Plot the fine-tuning loss and MAKE SURE TO SAVE IT AND SUBMIT IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training losses on x axis\n",
    "plt.plot(losses) # CODE\n",
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A revolving door is convenient for two direction travel, but it also serves as a security measure at a what? A.bank B.library C.department store D.mall E.new york\\nAnswer: ',\n",
       "  'A'),\n",
       " ('What do people aim to do at work? A.complete job B.learn from each other C.kill animals D.wear hats E.talk to each other\\nAnswer: ',\n",
       "  'A'),\n",
       " ('Where would you find magazines along side many other printed works? A.doctor B.bookstore C.market D.train station E.mortuary\\nAnswer: ',\n",
       "  'B'),\n",
       " ('Where are  you likely to find a hamburger? A.fast food restaurant B.pizza C.ground up dead cows D.mouth E.cow carcus\\nAnswer: ',\n",
       "  'A'),\n",
       " ('James was looking for a good place to buy farmland.  Where might he look? A.midwest B.countryside C.estate D.farming areas E.illinois\\nAnswer: ',\n",
       "  'A'),\n",
       " ('What island country is ferret popular? A.own home B.north carolina C.great britain D.hutch E.outdoors\\nAnswer: ',\n",
       "  'C'),\n",
       " (\"In what Spanish speaking North American country can you get a great cup of coffee? A.mildred's coffee shop B.mexico C.diner D.kitchen E.canteen\\nAnswer: \",\n",
       "  'B'),\n",
       " ('What do animals do when an enemy is approaching? A.feel pleasure B.procreate C.pass water D.listen to each other E.sing\\nAnswer: ',\n",
       "  'D'),\n",
       " ('Reading newspaper one of many ways to practice your what? A.literacy B.knowing how to read C.money D.buying E.money bank\\nAnswer: ',\n",
       "  'A'),\n",
       " ('What do people typically do while playing guitar? A.cry B.hear sounds C.singing D.arthritis E.making music\\nAnswer: ',\n",
       "  'C')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a few predictions on the eval dataset to see what the model predicts\n",
    "\n",
    "# construct a list of questions without the ground truth label\n",
    "# and compare prediction of the model with the ground truth\n",
    "\n",
    "def construct_test_samples(example):\n",
    "    \"\"\"\n",
    "    Helper for converting input examples which have \n",
    "    a separate qquestion, labels, answer options\n",
    "    into a single string for testing the model.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    example: dict\n",
    "        Sample input from the dataset which contains the \n",
    "        question, answer labels (e.g. A, B, C, D),\n",
    "        the answer options for the question, and which \n",
    "        of the answers is correct.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    input_text: str, str\n",
    "        Tuple: Formatted test text which contains the question,\n",
    "        the forwatted answer options (e.g., 'A. <option 1> B. <option 2>' etc); \n",
    "        the ground truth answer label only.\n",
    "    \"\"\"\n",
    "\n",
    "    answer_options_list = list(zip(\n",
    "        example[\"choices\"][\"label\"],\n",
    "        example[\"choices\"][\"text\"]\n",
    "    ))\n",
    "    # join each label and text with . and space\n",
    "    answer_options = \" \".join([f\"{label}.{text}\" for label, text in answer_options_list]) # CODE\n",
    "    # join the list of options with spaces into single string\n",
    "    answer_options_string = \" \".join(answer_options.split()) # CODE\n",
    "    # combine question and answer options\n",
    "    input_text = example[\"question\"] + \" \" + answer_options_string\n",
    "    # create the test input text which should be:\n",
    "    # the input text, followed by the string \"Answer: \"\n",
    "    # we don't need to append the ground truth answer since we are creating test inputs\n",
    "    # and the answer should be predicted.\n",
    "    input_text += \"\\nAnswer: \" # CODE\n",
    "\n",
    "    return input_text, example[\"answerKey\"]\n",
    "\n",
    "test_samples = [construct_test_samples(dataset[\"validation\"][i]) for i in range(10)]\n",
    "test_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One More Step: Test the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions of trained model  [('A revolving door is convenient for two direction travel, but it also serves as a security measure at a what? A.bank B.library C.department store D.mall E.new york\\nAnswer: ', 'A revolving door is convenient for two direction travel, but it also serves as a security measure at a what? A.bank B.library C.department store D.mall E.new york\\nAnswer:  B.', 'A'), ('What do people aim to do at work? A.complete job B.learn from each other C.kill animals D.wear hats E.talk to each other\\nAnswer: ', 'What do people aim to do at work? A.complete job B.learn from each other C.kill animals D.wear hats E.talk to each other\\nAnswer:  Sarah', 'A'), ('Where would you find magazines along side many other printed works? A.doctor B.bookstore C.market D.train station E.mortuary\\nAnswer: ', 'Where would you find magazines along side many other printed works? A.doctor B.bookstore C.market D.train station E.mortuary\\nAnswer:  Where would', 'B'), ('Where are  you likely to find a hamburger? A.fast food restaurant B.pizza C.ground up dead cows D.mouth E.cow carcus\\nAnswer: ', 'Where are  you likely to find a hamburger? A.fast food restaurant B.pizza C.ground up dead cows D.mouth E.cow carcus\\nAnswer:  C.', 'A'), ('James was looking for a good place to buy farmland.  Where might he look? A.midwest B.countryside C.estate D.farming areas E.illinois\\nAnswer: ', 'James was looking for a good place to buy farmland.  Where might he look? A.midwest B.countryside C.estate D.farming areas E.illinois\\nAnswer:  Where might', 'A'), ('What island country is ferret popular? A.own home B.north carolina C.great britain D.hutch E.outdoors\\nAnswer: ', 'What island country is ferret popular? A.own home B.north carolina C.great britain D.hutch E.outdoors\\nAnswer:  To make', 'C'), (\"In what Spanish speaking North American country can you get a great cup of coffee? A.mildred's coffee shop B.mexico C.diner D.kitchen E.canteen\\nAnswer: \", \"In what Spanish speaking North American country can you get a great cup of coffee? A.mildred's coffee shop B.mexico C.diner D.kitchen E.canteen\\nAnswer:  C.\", 'B'), ('What do animals do when an enemy is approaching? A.feel pleasure B.procreate C.pass water D.listen to each other E.sing\\nAnswer: ', 'What do animals do when an enemy is approaching? A.feel pleasure B.procreate C.pass water D.listen to each other E.sing\\nAnswer:  A.', 'D'), ('Reading newspaper one of many ways to practice your what? A.literacy B.knowing how to read C.money D.buying E.money bank\\nAnswer: ', 'Reading newspaper one of many ways to practice your what? A.literacy B.knowing how to read C.money D.buying E.money bank\\nAnswer:  C.', 'A'), ('What do people typically do while playing guitar? A.cry B.hear sounds C.singing D.arthritis E.making music\\nAnswer: ', 'What do people typically do while playing guitar? A.cry B.hear sounds C.singing D.arthritis E.making music\\nAnswer:  What is', 'C')]\n"
     ]
    }
   ],
   "source": [
    "# set it to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "for sample in test_samples:\n",
    "    input_text = sample[0]\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(\n",
    "        input_ids.input_ids,\n",
    "        attention_mask = input_ids.attention_mask,\n",
    "        max_new_tokens=2,\n",
    "        do_sample=True,\n",
    "        temperature=0.4,\n",
    "    )\n",
    "    prediction = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    predictions.append((input_text, prediction, sample[1]))\n",
    "\n",
    "print(\"Predictions of trained model \", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
