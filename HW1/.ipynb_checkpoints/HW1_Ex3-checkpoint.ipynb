{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Task overview <br>\n",
    "**Goal**: Practice fine-tuning a pre-trained LM (GPT2-small) on the particular task of commonsense question answering (QA) <br>\n",
    "**Dataset**: [CommonsenseQA](https://huggingface.co/datasets/tau/commonsense_qa) <br>\n",
    "**Description** <br>\n",
    "- Evaluate the performance of the model on testset over training set. <br>\n",
    "- Monitor: \n",
    "    - Whether the model’s performance is improving; \n",
    "    - Compare the performance of the base pretrained GPT-2 and the fine-tuned model \n",
    "- Steps:\n",
    "    1. Data preparation. Simiar to [sheet 1.1](https://cogsciprag.github.io/Understanding-LLMs-course/tutorials/01-introduction.html#main-training-data-processing-steps) and [sheet 2.3](https://cogsciprag.github.io/Understanding-LLMs-course/tutorials/02c-MLP-pytorch.html#preparing-the-training-data)\n",
    "    2. Load the pretrained GPT-2 model\n",
    "    3. Set up training pipiline. Steps similar to [sheet 2.5](https://cogsciprag.github.io/Understanding-LLMs-course/tutorials/02e-intro-to-hf.html)\n",
    "    4. Run the training while tracking the losses\n",
    "    5. Save plot of losses for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.30.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate) (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2023.12.2)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# pkg preparation\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "!pip3 install accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Data Preparation\n",
    "1. Acquiring data <br>\n",
    "2. Minimally exploring dataset <br>\n",
    "3. Cleaning / wrangling data (combines step 4 from sheet 1.1 and step 1.1 above) <br>\n",
    "4. Splitting data into training and test set (we will not do any hyperparam tuning) (we don't need further training set wrangling) <br>\n",
    "5. Tokenizing data and making sure it can be batched (i.e., conversted into 2d tensors, namely matrixes), this will also happen in our custom Dataset class (common practice when working with text data) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The keys are:\n",
      " dict_keys(['train', 'validation', 'test'])\n",
      "A sample:\n",
      " {'id': '075e483d21c29a511267ef62bedc0461', 'question': 'The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?', 'question_concept': 'punishing', 'choices': {'label': ['A', 'B', 'C', 'D', 'E'], 'text': ['ignore', 'enforce', 'authoritarian', 'yell at', 'avoid']}, 'answerKey': 'A'}\n"
     ]
    }
   ],
   "source": [
    "# downaload dataset from HF\n",
    "dataset = load_dataset(\"tau/commonsense_qa\")\n",
    "# inspect dataset, print all keys\n",
    "print(\"The keys are:\\n\", dataset.keys())\n",
    "# print a sample from the dataset\n",
    "print(\"A sample:\\n\", dataset[\"train\"][0]) # CODE\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# set padding side to be left because we are doing causal LM\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def massage_input_text(example):\n",
    "    \"\"\"\n",
    "    Helper for converting input examples which have \n",
    "    a separate question, labels, answer options\n",
    "    into a single string.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    example: dict\n",
    "        Sample input from the dataset which contains the \n",
    "        question, answer labels (e.g. A, B, C, D),\n",
    "        the answer options for the question, and which \n",
    "        of the answers is correct.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    input_text: str\n",
    "        Formatted training text which contains the question,\n",
    "        the formatted answer options (e.g., 'A. <option 1> B. <option 2>' etc)\n",
    "        and the ground truth answer.\n",
    "    \"\"\"\n",
    "    # combine each label with its corresponding text\n",
    "    # answer_options_list = list(zip(\n",
    "    #    example[\"choices\"][\"label\"],\n",
    "    #    example[\"choices\"][\"text\"]\n",
    "    # )) I'VE REWRITTEN INTO PIECES\n",
    "    # obtain label list\n",
    "    labels = example[\"choices\"][\"label\"]\n",
    "    # obtain text list\n",
    "    texts = example[\"choices\"][\"text\"]\n",
    "    # using zip to match text with labels\n",
    "    zipped_pairs = zip(labels, texts)\n",
    "    # return zip pairs to list\n",
    "    answer_options_list = list(zipped_pairs)\n",
    "\n",
    "    # join each label and text with . and space # as \"A. Option 1 B. Option 2 C. Option 3\" \n",
    "    # CODE\n",
    "    formatted_options = []\n",
    "    for label, text in answer_options_list:\n",
    "        formatted_options.append(f\"{label}. {text}\")\n",
    "    answer_options = \" \".join(formatted_options)\n",
    "    \n",
    "    # join the list of options with spaces into single string\n",
    "    # CODE\n",
    "    # cut string into list and delete redundant spaces\n",
    "    options_list = answer_options.split()\n",
    "    # connect list elements into a string\n",
    "    answer_options_string = \" \".join(options_list)\n",
    "    \n",
    "    # combine question and answer options\n",
    "    input_text = example[\"question\"] + \" \" + answer_options_string\n",
    "    # append the true answer with a new line, \"Answer: \" and the label\n",
    "    input_text += \"\\nAnswer: \" + example[\"answerKey\"]\n",
    "    \n",
    "    return input_text\n",
    "\n",
    "# process input texts of train and test sets\n",
    "massaged_datasets = dataset.map(\n",
    "    lambda example: {\n",
    "        \"text\": massage_input_text(example)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sample from the preprocessed data:\n",
      " The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? A. ignore B. enforce C. authoritarian D. yell at E. avoid\n",
      "Answer: A\n"
     ]
    }
   ],
   "source": [
    "# inspect a sample from our preprocessed data\n",
    "print(\"A sample from the preprocessed data:\\n\", massaged_datasets[\"train\"][0]['text']) # SRC, modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommonsenseQADataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset class for CommonsenseQA dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            train_split, \n",
    "            test_split,\n",
    "            tokenizer,\n",
    "            max_length=64,\n",
    "            dataset_split=\"train\",\n",
    "        ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the dataset object.\n",
    "        \n",
    "        Arguments\n",
    "        ---------\n",
    "        train_split: dict\n",
    "            Training data dictionary with different columns.\n",
    "        test_split: dict\n",
    "            Test data dictionary with different columns.\n",
    "        tokenizer: Tokenizer\n",
    "            Initialized tokenizer for processing samples.\n",
    "        max_length: int\n",
    "            Maximal length of inputs. All inputs will be \n",
    "            truncated or padded to this length.\n",
    "        dataset_split: str\n",
    "            Specifies which split of the dataset to use. \n",
    "            Default is \"train\".\n",
    "        \"\"\"\n",
    "        self.train_split = train_split['text']\n",
    "        self.test_split = test_split['text']\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.dataset_split = dataset_split\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Method returning the length of the training dataset.\n",
    "        \"\"\"\n",
    "        return len(self.train_split) if self.dataset_split == \"train\" else len(self.test_split) # CODE\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Method returning a single training example.\n",
    "        Note that it also tokenizes, truncates or pads the input text. \n",
    "        # Padding（填充），通常用于保证输入序列的长度一致性\n",
    "        Further, it creates a mask tensor for the input text which \n",
    "        is used for causal masking in the transformer model.\n",
    "        # causal mask（掩码），用于确保模型在预测时不会窥探到未来的信息。\n",
    "        # ~ tensor，its data structure 在每个位置生成一个与输入序列相同长度的掩码张量，\n",
    "        # 其中包含了特殊的值来表示哪些位置是有效的（可以参与计算）以及哪些位置是无效的（需要被掩盖）\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        idx: int\n",
    "            Index of training sample to be retrieved from the data.\n",
    "        \n",
    "        Returns\n",
    "        --------\n",
    "        tokenized_input: dict\n",
    "            Dictionary with input_ids (torch.Tensor) and an attention_mask\n",
    "            (torch.Tensor).\n",
    "        \"\"\"\n",
    "        # retrieve a training sample at the specified index idx\n",
    "        # HINT: note that this might depend on self.dataset_split\n",
    "        input_text = self.train_split[idx] if self.dataset_split == \"train\" else self.test_split[idx] # CODE\n",
    "        tokenized_input = self.tokenizer(\n",
    "            input_text,\n",
    "            max_length = self.max_length, # CODE\n",
    "            padding = \"max_length\",\n",
    "            truncation = True,\n",
    "            return_tensors = \"pt\"\n",
    "        )\n",
    "\n",
    "        # Create a mask tensor for the input text for causal masking in the transformer model\n",
    "        # The mask tensor marks which positions in the input are valid (1) and which are padded (0)\n",
    "        tokenized_input[\"attention_mask\"] = (tokenized_input[\"input_ids\"] != tokenizer.pad_token_id).long()\n",
    "        \n",
    "        return tokenized_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# move to accelerated device \n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Device: {device}\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(f\"Device: {device}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Initialise Model\n",
    "Hint: If you run out of memory while trying to run the training, try decreasing the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 size: 124.4 M parameters\n"
     ]
    }
   ],
   "source": [
    "# load pretrained gpt2 using the Transformer library provided by HF (Hugging Face)\n",
    "# call the `from transformers import AutoModelForCausalLM at the beginning`\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\") # CODE\n",
    "# print num of trainable parameters\n",
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"GPT-2 size: {model_size/1000**2:.1f} M parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Set up configurations required for the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate dataset with the downloaded commonsense_qa data \n",
    "train_dataset = CommonsenseQADataset(\n",
    "    train_split = massaged_datasets[\"train\"], \n",
    "    test_split = massaged_datasets[\"test\"],\n",
    "    tokenizer = tokenizer,\n",
    "    max_length = 64, \n",
    "    dataset_split = \"train\" # CODE\n",
    ")\n",
    "# instantiate test dataset with the downloaded commonsense_qa data\n",
    "test_dataset = CommonsenseQADataset(\n",
    "    train_split = massaged_datasets[\"train\"], \n",
    "    test_split = massaged_datasets[\"test\"],\n",
    "    tokenizer = tokenizer,\n",
    "    max_length = 64, \n",
    "    dataset_split = \"test\" # CODE\n",
    ")\n",
    "# create a DataLoader for the dataset\n",
    "# the data loader will automatically batch the data\n",
    "# and iteratively return training examples (question answer pairs) in batches\n",
    "dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True\n",
    ")\n",
    "# create a DataLoader for the test dataset\n",
    "# reason for separate data loader is that we want to\n",
    "# be able to use a different index for retreiving the test batches\n",
    "# we might also want to use a different batch size etc.\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=32, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Run the training of the model\n",
    "Hint: for implementing the forward pass and loss computation, carefully look at the exercise sheets and the links to examples in HF tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training steps:  304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/304 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 0, loss 8.360413551330566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▏                                        | 1/304 [00:34<2:56:23, 34.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(10.1301)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▎                                      | 10/304 [03:46<1:40:08, 20.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 10, loss 3.0161397457122803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▍                                      | 11/304 [04:26<2:08:06, 26.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(2.8817)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▋                                     | 20/304 [07:12<1:27:54, 18.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 20, loss 2.1948773860931396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|██▊                                     | 21/304 [07:42<1:44:38, 22.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(2.2421)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▉                                    | 30/304 [09:53<1:07:50, 14.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 30, loss 1.9785974025726318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████                                    | 31/304 [10:20<1:24:09, 18.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(2.0365)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▎                                  | 40/304 [12:48<1:12:34, 16.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 40, loss 1.8595573902130127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█████▍                                  | 41/304 [13:20<1:33:04, 21.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.8555)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▌                                 | 50/304 [16:04<1:17:59, 18.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 50, loss 1.8535109758377075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████▋                                 | 51/304 [16:35<1:33:17, 22.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.8752)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▉                                | 60/304 [18:56<1:04:09, 15.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 60, loss 1.979228138923645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████                                | 61/304 [19:28<1:23:59, 20.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.9207)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████▏                              | 70/304 [22:19<1:08:14, 17.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 70, loss 1.7095940113067627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|█████████▎                              | 71/304 [22:59<1:33:51, 24.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7499)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████                               | 80/304 [25:19<59:47, 16.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 80, loss 1.676868200302124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██████████▋                             | 81/304 [25:48<1:13:16, 19.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.8711)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████▊                            | 90/304 [28:12<1:00:41, 17.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 90, loss 1.6977488994598389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████▉                            | 91/304 [28:42<1:14:11, 20.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7855)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|█████████████▍                           | 100/304 [30:52<49:22, 14.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 100, loss 1.5824917554855347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|████████████▉                          | 101/304 [31:19<1:01:27, 18.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7894)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████▊                          | 110/304 [33:18<44:36, 13.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 110, loss 1.6907202005386353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████▉                          | 111/304 [33:45<57:07, 17.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.8000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|████████████████▏                        | 120/304 [35:31<35:03, 11.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 120, loss 1.6692423820495605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████████████████▎                        | 121/304 [35:55<45:49, 15.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.8261)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████▌                       | 130/304 [37:48<38:18, 13.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 130, loss 1.8414536714553833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████▋                       | 131/304 [38:16<50:30, 17.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.8468)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████▉                      | 140/304 [40:18<37:51, 13.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 140, loss 1.652242660522461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████                      | 141/304 [40:46<49:03, 18.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.8872)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████████████████████▏                    | 150/304 [42:56<37:09, 14.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 150, loss 1.6028579473495483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████████████████████▎                    | 151/304 [43:23<46:18, 18.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.8101)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████▌                   | 160/304 [45:45<37:14, 15.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 160, loss 1.6355931758880615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████████████████████▋                   | 161/304 [46:12<45:16, 19.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7923)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████▉                  | 170/304 [48:31<33:49, 15.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 170, loss 1.4633604288101196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|███████████████████████                  | 171/304 [48:56<40:14, 18.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7713)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|████████████████████████▎                | 180/304 [51:10<31:12, 15.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 180, loss 1.5777430534362793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████▍                | 181/304 [51:41<41:03, 20.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7753)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|█████████████████████████▋               | 190/304 [53:52<26:27, 13.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 190, loss 1.562142252922058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|█████████████████████████▊               | 191/304 [54:20<34:23, 18.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7437)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████▉              | 200/304 [56:39<28:15, 16.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 200, loss 1.5763251781463623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|███████████████████████████              | 201/304 [57:10<35:47, 20.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7589)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████▎            | 210/304 [59:13<22:01, 14.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 210, loss 1.5135680437088013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|████████████████████████████▍            | 211/304 [59:41<28:15, 18.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.6668)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|████████████████████████████▏          | 220/304 [1:01:52<20:03, 14.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 220, loss 1.5170212984085083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|████████████████████████████▎          | 221/304 [1:02:20<25:28, 18.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7239)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████▌         | 230/304 [1:04:19<15:49, 12.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 230, loss 1.5646878480911255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████▋         | 231/304 [1:04:44<20:05, 16.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7458)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████▊        | 240/304 [1:06:55<16:06, 15.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 240, loss 1.4266479015350342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|██████████████████████████████▉        | 241/304 [1:07:20<19:03, 18.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.8017)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████████████████████████████       | 250/304 [1:09:29<11:50, 13.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 250, loss 1.5224792957305908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████████████████████████████▏      | 251/304 [1:09:52<14:18, 16.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.8791)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████▎     | 260/304 [1:11:55<10:08, 13.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 260, loss 1.3911792039871216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████▍     | 261/304 [1:12:27<13:49, 19.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7253)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|██████████████████████████████████▋    | 270/304 [1:14:27<07:39, 13.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 270, loss 1.499648094177246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|██████████████████████████████████▊    | 271/304 [1:14:59<10:30, 19.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.8023)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████▉   | 280/304 [1:17:14<05:26, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 280, loss 1.5604753494262695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|████████████████████████████████████   | 281/304 [1:17:57<08:37, 22.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7205)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████████████████████████████████▏ | 290/304 [1:20:33<04:14, 18.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 290, loss 1.3355660438537598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████▎ | 291/304 [1:21:10<05:07, 23.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.7418)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|██████████████████████████████████████▍| 300/304 [1:23:49<01:04, 16.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 300, loss 1.4365522861480713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|██████████████████████████████████████▌| 301/304 [1:24:17<00:58, 19.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  tensor(1.8259)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 304/304 [1:25:04<00:00, 16.79s/it]\n"
     ]
    }
   ],
   "source": [
    "# put the model in training mode\n",
    "model.train()\n",
    "# move the model to the device (e.g. GPU)\n",
    "model = model.to(device)\n",
    "\n",
    "# trianing configutations \n",
    "# feel free to play around with these\n",
    "epochs  = 1\n",
    "train_steps =  len(train_dataset) // 32\n",
    "print(\"Number of training steps: \", train_steps)\n",
    "# number of test steps to perform every 10 training steps\n",
    "# (smaller that the entore test split for reasons of comp. time)\n",
    "num_test_steps = 5\n",
    "\n",
    "# define optimizer and learning rate\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4) \n",
    "# define some variables to accumulate the losses\n",
    "losses = []\n",
    "test_losses = []\n",
    "\n",
    "# iterate over epochs\n",
    "for e in range(epochs):\n",
    "    # iterate over training steps\n",
    "    for i in tqdm(range(train_steps)):\n",
    "        # get a batch of data\n",
    "        x = next(iter(dataloader))\n",
    "        # move the data to the device (GPU)\n",
    "        x = x.to(device) # CODE\n",
    "\n",
    "        # forward pass through the model \n",
    "        inputs = {key: val.to(device) for key, val in x.items()} # CODE\n",
    "        outputs = model(\n",
    "            **inputs,\n",
    "            labels = inputs[\"input_ids\"]) # CODE\n",
    "        # get the loss\n",
    "        loss = outputs.loss # CODE\n",
    "        # backward pass\n",
    "        loss.backward() # CODE\n",
    "        losses.append(loss.item())\n",
    "        # update the parameters of the model\n",
    "        optimizer.step() # CODE\n",
    "\n",
    "        # zero out gradient for next step\n",
    "        optimizer.zero_grad() # CODE\n",
    "\n",
    "        # evaluate on test set every 10 steps\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch {e}, step {i}, loss {loss.item()}\")\n",
    "            # track test loss for the evaluation iteration\n",
    "            test_loss = 0\n",
    "            for j in range(num_test_steps):\n",
    "                # get test batch\n",
    "                x_test = next(iter(test_dataloader))\n",
    "                x_test = x_test.to(device)\n",
    "                with torch.no_grad():\n",
    "                    test_outputs = model(\n",
    "                        **x_test,\n",
    "                        labels=x_test[\"input_ids\"] # CODE\n",
    "                    )\n",
    "                if test_outputs.loss is not None: # Check of the loss is not None\n",
    "                    test_loss += test_outputs.loss # CODE\n",
    "                \n",
    "            test_losses.append(test_loss / num_test_steps)\n",
    "            print(\"Test loss: \", test_loss/num_test_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Plot the fine-tuning loss and MAKE SURE TO SAVE IT AND SUBMIT IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training losses on x axis\n",
    "plt.plot(losses) # CODE\n",
    "plt.xlabel(\"Training steps\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A revolving door is convenient for two direction travel, but it also serves as a security measure at a what? A.bank B.library C.department store D.mall E.new york\n",
      "Answer:  A\n",
      "What do people aim to do at work? A.complete job B.learn from each other C.kill animals D.wear hats E.talk to each other\n",
      "Answer:  A\n",
      "Where would you find magazines along side many other printed works? A.doctor B.bookstore C.market D.train station E.mortuary\n",
      "Answer:  B\n",
      "Where are  you likely to find a hamburger? A.fast food restaurant B.pizza C.ground up dead cows D.mouth E.cow carcus\n",
      "Answer:  A\n",
      "James was looking for a good place to buy farmland.  Where might he look? A.midwest B.countryside C.estate D.farming areas E.illinois\n",
      "Answer:  A\n",
      "What island country is ferret popular? A.own home B.north carolina C.great britain D.hutch E.outdoors\n",
      "Answer:  C\n",
      "In what Spanish speaking North American country can you get a great cup of coffee? A.mildred's coffee shop B.mexico C.diner D.kitchen E.canteen\n",
      "Answer:  B\n",
      "What do animals do when an enemy is approaching? A.feel pleasure B.procreate C.pass water D.listen to each other E.sing\n",
      "Answer:  D\n",
      "Reading newspaper one of many ways to practice your what? A.literacy B.knowing how to read C.money D.buying E.money bank\n",
      "Answer:  A\n",
      "What do people typically do while playing guitar? A.cry B.hear sounds C.singing D.arthritis E.making music\n",
      "Answer:  C\n"
     ]
    }
   ],
   "source": [
    "# print a few predictions on the eval dataset to see what the model predicts\n",
    "\n",
    "# construct a list of questions without the ground truth label\n",
    "# and compare prediction of the model with the ground truth\n",
    "\n",
    "def construct_test_samples(example):\n",
    "    \"\"\"\n",
    "    Helper for converting input examples which have \n",
    "    a separate qquestion, labels, answer options\n",
    "    into a single string for testing the model.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    example: dict\n",
    "        Sample input from the dataset which contains the \n",
    "        question, answer labels (e.g. A, B, C, D),\n",
    "        the answer options for the question, and which \n",
    "        of the answers is correct.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    input_text: str, str\n",
    "        Tuple: Formatted test text which contains the question,\n",
    "        the forwatted answer options (e.g., 'A. <option 1> B. <option 2>' etc); \n",
    "        the ground truth answer label only.\n",
    "    \"\"\"\n",
    "\n",
    "    answer_options_list = list(zip(\n",
    "        example[\"choices\"][\"label\"],\n",
    "        example[\"choices\"][\"text\"]\n",
    "    ))\n",
    "    # join each label and text with . and space\n",
    "    answer_options = \" \".join([f\"{label}.{text}\" for label, text in answer_options_list]) # CODE\n",
    "    # join the list of options with spaces into single string\n",
    "    answer_options_string = \" \".join(answer_options.split()) # CODE\n",
    "    # combine question and answer options\n",
    "    input_text = example[\"question\"] + \" \" + answer_options_string\n",
    "    # create the test input text which should be:\n",
    "    # the input text, followed by the string \"Answer: \"\n",
    "    # we don't need to append the ground truth answer since we are creating test inputs\n",
    "    # and the answer should be predicted.\n",
    "    input_text += \"\\nAnswer: \" # CODE\n",
    "\n",
    "    return input_text, example[\"answerKey\"]\n",
    "\n",
    "test_samples = [construct_test_samples(dataset[\"validation\"][i]) for i in range(10)]\n",
    "for sample in test_samples:\n",
    "    print(sample[0], sample[1]) # SRC modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One More Step: Test the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions of trained model:\n",
      "Question:  A revolving door is convenient for two direction travel, but it also serves as a security measure at a what? A.bank B.library C.department store D.mall E.new york\n",
      "Answer:  C.\n",
      "True Answer:  A\n",
      "Question:  What do people aim to do at work? A.complete job B.learn from each other C.kill animals D.wear hats E.talk to each other\n",
      "Answer:  What is\n",
      "True Answer:  A\n",
      "Question:  Where would you find magazines along side many other printed works? A.doctor B.bookstore C.market D.train station E.mortuary\n",
      "Answer:  A.\n",
      "True Answer:  B\n",
      "Question:  Where are  you likely to find a hamburger? A.fast food restaurant B.pizza C.ground up dead cows D.mouth E.cow carcus\n",
      "Answer:  A.\n",
      "True Answer:  A\n",
      "Question:  James was looking for a good place to buy farmland.  Where might he look? A.midwest B.countryside C.estate D.farming areas E.illinois\n",
      "Answer:  C.\n",
      "True Answer:  A\n",
      "Question:  What island country is ferret popular? A.own home B.north carolina C.great britain D.hutch E.outdoors\n",
      "Answer:  C.\n",
      "True Answer:  C\n",
      "Question:  In what Spanish speaking North American country can you get a great cup of coffee? A.mildred's coffee shop B.mexico C.diner D.kitchen E.canteen\n",
      "Answer:  A.\n",
      "True Answer:  B\n",
      "Question:  What do animals do when an enemy is approaching? A.feel pleasure B.procreate C.pass water D.listen to each other E.sing\n",
      "Answer:  What can\n",
      "True Answer:  D\n",
      "Question:  Reading newspaper one of many ways to practice your what? A.literacy B.knowing how to read C.money D.buying E.money bank\n",
      "Answer:  A.\n",
      "True Answer:  A\n",
      "Question:  What do people typically do while playing guitar? A.cry B.hear sounds C.singing D.arthritis E.making music\n",
      "Answer:  A.\n",
      "True Answer:  C\n"
     ]
    }
   ],
   "source": [
    "# set it to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "for sample in test_samples:\n",
    "    input_text = sample[0]\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "    output = model.generate(\n",
    "        input_ids.input_ids,\n",
    "        attention_mask = input_ids.attention_mask,\n",
    "        max_new_tokens=2,\n",
    "        do_sample=True,\n",
    "        temperature=0.4,\n",
    "    )\n",
    "    prediction = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    predictions.append((input_text, prediction, sample[1]))\n",
    "\n",
    "print(\"Predictions of trained model:\")\n",
    "for prediction in predictions:\n",
    "    print(\"Question: \", prediction[1])  # predicted\n",
    "    print(\"True Answer: \", prediction[2])  # true\n",
    "    # SRC modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions:\n",
    "1. **Provide a brief description of the CommonsenseQA dataset. What kind of task was it developed for, what do the single columns contain?** <br>\n",
    "\n",
    "It is designed for the task of commonsense reasoning. It contains questions with possible answers based on commonsense knowledge. The columns include: <br>\n",
    "a. Question: query to be answered\n",
    "b. Multiple choices: possible answers with labels indicating each option.\n",
    "c. Answer Key: the correct answers indicating by labels\n",
    "\n",
    "2. **What loss function is computed for this training? Provide the name of the function (conceptual, not necessarily the name of a function in the code).** <br>\n",
    "\n",
    "It's cross-entropy loss.\n",
    "\n",
    "3. **Given your loss curve, do you think your model will perform well on answering common sense questions? (Note: there is no single right answer, you need to interpret your specific plot)** <br>\n",
    "\n",
    "Yes as the fluctations in the early stage of training shown in the loss curve is becoming stable.\n",
    "\n",
    "4. **Inspect the predictions above. On how many test questions did the model predict the right answer? Compute the accuracy.** <br>\n",
    "\n",
    "I think there is sth wrong with my codes as 1/ some predicted answers are not labels but texts, 2/ the accuracy is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Store no. of correct predictions\n",
    "correct_predictions = 0\n",
    "total_predictions = len(predictions)\n",
    "\n",
    "for prediction in spredictions:\n",
    "    \n",
    "    if prediction[1].strip() == prediction[2].strip(): \n",
    "        correct_predictions += 1\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "# Print accuracy\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
